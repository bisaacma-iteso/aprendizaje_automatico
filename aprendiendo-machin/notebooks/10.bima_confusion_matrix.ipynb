{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import huggingface_hub\n",
    "from datasets import load_dataset\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import cupy as cp\n",
    "import gc\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from skimage import color, exposure, filters, util, morphology\n",
    "from skimage import img_as_ubyte, img_as_float\n",
    "from skimage.filters import rank\n",
    "from skimage.filters import gaussian\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# CUDA/GPU\n",
    "from cuml.decomposition import PCA as cuPCA\n",
    "from cuml.preprocessing import minmax_scale as cuml_minmax_scale\n",
    "from cuml.svm import LinearSVC as cuLinearSVC\n",
    "from cuml.neighbors import KNeighborsClassifier as cuKNN\n",
    "from cuml.svm import SVC as cuSVC\n",
    "from cuml.manifold import UMAP\n",
    "from cuml.model_selection import train_test_split\n",
    "import cudf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_gaussian_filter(image, sigma=6):\n",
    "    # Create a Gaussian mask that varies only horizontally based on distance from the center\n",
    "    height, width = image.shape\n",
    "    y, x = np.ogrid[:height, :width]\n",
    "    center_x = width / 2\n",
    "\n",
    "    # Create a Gaussian mask\n",
    "    # sigma = Standard deviation for the Gaussian function\n",
    "    mask = np.exp(-((x - center_x)**2) / (2 * sigma**2))\n",
    "\n",
    "    # Apply the Gaussian mask to the image\n",
    "    masked_image = image * mask\n",
    "\n",
    "    # Scale the masked image to 0-255\n",
    "    masked_image_scaled = (masked_image - np.min(masked_image)) / (np.max(masked_image) - np.min(masked_image)) * 255\n",
    "    masked_image_scaled = masked_image_scaled.astype(np.uint8)\n",
    "\n",
    "    return masked_image_scaled, mask\n",
    "\n",
    "def remove_borders(image, reduce_factor=0.1):\n",
    "    # Define the border width as 10% of the image size\n",
    "    border_size = int(32 * reduce_factor)\n",
    "\n",
    "    blackout_image = image.copy()\n",
    "    # Set the border regions to black (0)\n",
    "    # Top border\n",
    "    blackout_image[:border_size, :] = 0\n",
    "    # Bottom border\n",
    "    blackout_image[-border_size:, :] = 0\n",
    "    # Left border\n",
    "    blackout_image[:, :border_size] = 0\n",
    "    # Right border\n",
    "    blackout_image[:, -border_size:] = 0\n",
    "\n",
    "    return blackout_image\n",
    "\n",
    "def find_contours(image):\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(image, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    # Create a blank image to draw contours on\n",
    "    contour_only_image = np.zeros_like(image)\n",
    "    cv2.drawContours(contour_only_image, contours, -1, 255, 1)  # Draw contours in white (255)\n",
    "    return contour_only_image\n",
    "\n",
    "def sharpen_image(image, filter=(5,5)):\n",
    "    # Sharpen image\n",
    "    blurred = cv2.GaussianBlur(image, filter, 0)\n",
    "    return cv2.addWeighted(image, 1.5, blurred, -0.5, 0)\n",
    "\n",
    "def apply_median_filter(image):\n",
    "    # Step 2: Reduce the impact of outliers using median filter\n",
    "    selem = morphology.disk(2)\n",
    "    return filters.rank.median(img_as_ubyte(image), selem)\n",
    "\n",
    "def apply_log_filter(image):\n",
    "    # Create a FunctionTransformer for the log transformation\n",
    "    log_transformer = FunctionTransformer(np.log1p, validate=True)\n",
    "\n",
    "    # Apply the log transformation\n",
    "    transformed_image = log_transformer.fit_transform(image)\n",
    "\n",
    "    # Rescale the transformed image back to [0, 255]\n",
    "    transformed_image = (transformed_image / np.max(transformed_image)) * 255\n",
    "    return transformed_image.astype(np.uint8)\n",
    "\n",
    "def pipeline(ds,\n",
    "             labels_ds,\n",
    "             clahe_clipLimit=2.0,\n",
    "             clahe_tileGridSize=(3,3),\n",
    "             sharpen_filter=(5,5),\n",
    "             gaussian_sigma=6,\n",
    "             extra_filter=None,\n",
    "             random_sample_id= None,\n",
    "             debug=False\n",
    "             ):\n",
    "    \"\"\" \n",
    "    Assumes input dataset are N samples of RGB images, 32x32 (32, 32, 3) shape.\n",
    "    Input must be a np-array with images only.\n",
    "    Transforms from RGB (3-channels) to a single grayscale channel\n",
    "    Applies Gaussian weighting to remove distractions in borders\n",
    "    Actual digit is centered\n",
    "\n",
    "    Returns modified dataset\n",
    "    \"\"\"\n",
    "    # Initialize an array to hold the grayscale images\n",
    "    new_dataset = np.empty((len(ds), 32, 32), dtype=np.uint8)\n",
    "\n",
    "    if (random_sample_id is None) and debug:\n",
    "        random_sample_id = random.randint(0, len(ds))\n",
    "    \n",
    "    if debug:\n",
    "        original_random_image = ds[random_sample_id]\n",
    "        original_random_label = labels_ds[random_sample_id]\n",
    "\n",
    "    # Step 1: Convert images to grayscale\n",
    "    gray_images = (color.rgb2gray(ds) * 255).astype(np.uint8)\n",
    "\n",
    "    # Iterate per-image\n",
    "    total_images_processed = 0\n",
    "    for i in range(0, len(gray_images)):\n",
    "        \n",
    "        total_images_processed +=1\n",
    "        gray_image = gray_images[i]\n",
    "\n",
    "        # Sharpening\n",
    "        sharpened_image = sharpen_image(gray_image, sharpen_filter)\n",
    "\n",
    "        # CLAHE\n",
    "        clahe = cv2.createCLAHE(clipLimit=clahe_clipLimit, tileGridSize=clahe_tileGridSize)\n",
    "        clahe_image = clahe.apply(sharpened_image)\n",
    "\n",
    "        # Median filter\n",
    "        median_filtered_image = apply_median_filter(clahe_image)\n",
    "\n",
    "        # Log filter\n",
    "        log_filtered_image = apply_log_filter(clahe_image)\n",
    "\n",
    "        image_for_binary = clahe_image\n",
    "        if (extra_filter==\"log\"):\n",
    "            image_for_binary = log_filtered_image\n",
    "        if (extra_filter==\"median\"):\n",
    "            image_for_binary = median_filtered_image\n",
    "\n",
    "        # Use binary threshold to reduce everything to 2 colors\n",
    "        _, binary_image = cv2.threshold(image_for_binary, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "        #print(f'mean_binary: {np.mean(binary_image)}')\n",
    "\n",
    "        # Get contours\n",
    "        contour_image = find_contours(binary_image)\n",
    "\n",
    "        # Gaussian filter\n",
    "        masked_image_scaled, mask = apply_gaussian_filter(binary_image, gaussian_sigma)\n",
    "\n",
    "        new_dataset[i] = masked_image_scaled\n",
    "\n",
    "        # Log filter\n",
    "        # log_filtered_image = apply_log_filter(median_filtered_image)\n",
    "\n",
    "        if (i == random_sample_id) and debug:\n",
    "            # List of image data and titles for each row\n",
    "            images = [\n",
    "                (original_random_image, gray_image),       # Row 1 images\n",
    "                (sharpened_image, clahe_image),             # Row 2 images\n",
    "                (log_filtered_image, median_filtered_image),          # Row 3 images\n",
    "                (binary_image, contour_image),                     # Row 4 images\n",
    "                (mask, masked_image_scaled)                # Row 5 image (second image is None)\n",
    "            ]\n",
    "\n",
    "            # List of titles for each row\n",
    "            titles = [\n",
    "                (\"Imagen Original\", \"Escala de Grises\"),\n",
    "                (\"Sharpening\", \"CLAHE\"),\n",
    "                (\"CLAHE + Log\", \"CLAHE + Median\"),\n",
    "                (\"Binary Dynamic Threshold\", \"Contornos\"),\n",
    "                (\"MÃ¡scara Gaussiana\", \"Imagen enmascarada\")  # No second title for this row\n",
    "            ]\n",
    "\n",
    "            # Loop over the rows to create and save individual images for each row\n",
    "            for i, (row_images, row_titles) in enumerate(zip(images, titles)):\n",
    "                # Create a figure for the current row\n",
    "                fig, axes = plt.subplots(1, 2, figsize=(12, 6))  # 1 row, 2 images per row\n",
    "\n",
    "                primer_paso = i*2\n",
    "                segundo_paso = (i*2)+1\n",
    "                #fig.suptitle(f'Pasos {primer_paso} y {segundo_paso}', fontsize=16)\n",
    "\n",
    "                # Plot the first image in the row\n",
    "                axes[0].imshow(row_images[0], cmap='gray')\n",
    "                axes[0].set_title(row_titles[0])\n",
    "                axes[0].axis('off')\n",
    "\n",
    "                # If there is a second image, plot it\n",
    "                if row_images[1] is not None:\n",
    "                    axes[1].imshow(row_images[1], cmap='gray')\n",
    "                    axes[1].set_title(row_titles[1])\n",
    "                    axes[1].axis('off')\n",
    "                else:\n",
    "                    axes[1].axis('off')  # Hide the second axis if no second image\n",
    "\n",
    "                # Save the image for the current row\n",
    "                plt.subplots_adjust(wspace=0.3, hspace=0.3)  # Adjust spacing if necessary\n",
    "\n",
    "                plt.savefig(f'row_{i+1}_images.png', dpi=300, bbox_inches='tight')  # Save each row's image\n",
    "                #plt.close()  # Close the figure to free up memory\n",
    "\n",
    "    return new_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing transformer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreprocessingTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,\n",
    "                 clahe_clipLimit=2.0,\n",
    "                 clahe_tileGridSize=(3, 3),\n",
    "                 sharpen_filter=(5, 5), \n",
    "                 gaussian_sigma=6,\n",
    "                 extra_filter=None,\n",
    "                 random_sample_id=None,\n",
    "                 debug=False,\n",
    "                 use_gpu=False):\n",
    "        # Store preprocessing parameters\n",
    "        self.clahe_clipLimit = clahe_clipLimit\n",
    "        self.clahe_tileGridSize = clahe_tileGridSize\n",
    "        self.sharpen_filter = sharpen_filter\n",
    "        self.gaussian_sigma = gaussian_sigma\n",
    "        self.extra_filter = extra_filter\n",
    "        self.random_sample_id = random_sample_id\n",
    "        self.debug = debug\n",
    "        self.use_gpu = use_gpu\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # This method can stay empty since we don't need fitting for preprocessing\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "\n",
    "        # CPU-only processed data\n",
    "        processed_data = pipeline(\n",
    "            ds=X, \n",
    "            labels_ds=y, \n",
    "            clahe_clipLimit=self.clahe_clipLimit, \n",
    "            clahe_tileGridSize=self.clahe_tileGridSize, \n",
    "            sharpen_filter=self.sharpen_filter, \n",
    "            gaussian_sigma=self.gaussian_sigma, \n",
    "            extra_filter=self.extra_filter, \n",
    "            random_sample_id=self.random_sample_id,\n",
    "            debug=self.debug\n",
    "        )\n",
    "\n",
    "        # Flatten data\n",
    "        processed_data = processed_data.reshape(processed_data.shape[0], -1)\n",
    "\n",
    "        # Convert data to GPU if needed\n",
    "        if self.use_gpu:\n",
    "            # Scale the data on GPU\n",
    "            processed_data = cuml_minmax_scale(processed_data, feature_range=(0, 1))\n",
    "    \n",
    "            # Convert to cudf DataFrame on GPU\n",
    "            processed_data = cudf.DataFrame.from_pandas(pd.DataFrame(processed_data)).to_cupy()\n",
    "        else:\n",
    "            scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "            processed_data = scaler.fit_transform(processed_data)\n",
    "            \n",
    "        return processed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import cropped-digits dataset\n",
    "dataset_cropped_digits_raw = load_dataset(\"ufldl-stanford/svhn\",\n",
    "                                          \"cropped_digits\",\n",
    "                                          cache_dir='../data/svhn/')\n",
    "\n",
    "# Get dataset subsets\n",
    "ds_train = dataset_cropped_digits_raw[\"train\"]\n",
    "ds_test = dataset_cropped_digits_raw[\"test\"]\n",
    "\n",
    "ds_train_images = np.array(ds_train[\"image\"])\n",
    "ds_test_images = np.array(ds_test[\"image\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np.array(ds_train[\"label\"])\n",
    "Y_test =  np.array(ds_test[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use SMOTE for skewed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataset subsets\n",
    "\n",
    "# Step 1: Flatten images (from 32x32x3 to 3072-dimensional vectors)\n",
    "X_train = ds_train_images.reshape(ds_train_images.shape[0], -1)  # Shape (num_samples, 32*32*3)\n",
    "X_test = ds_test_images.reshape(ds_test_images.shape[0], -1)\n",
    "\n",
    "# Step 2: Normalize images to [0, 1]\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "# Step 3: Apply SMOTE to balance the training dataset\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train, Y_train = smote.fit_resample(X_train, Y_train)\n",
    "\n",
    "# Step 4: Optionally, reshape back to original image dimensions (32x32x3)\n",
    "X_train = X_train.reshape(X_train.shape[0], 32, 32, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess data\n",
    "\n",
    "#Best parameters: {'preprocessing__gaussian_sigma': 6, 'preprocessing__extra_filter': 'median', 'pca__n_components': 47, 'knn__n_neighbors': 30}\n",
    "\n",
    "#Best score: 0.7265673279762268"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = PreprocessingTransformer(gaussian_sigma=6,\n",
    "                                       extra_filter='median',\n",
    "                                       debug=True,\n",
    "                                       random_sample_id=0)\n",
    "\n",
    "X_pca_train = transformer.transform(X=np.expand_dims(ds_train_images[42],\n",
    "                                    axis=0),\n",
    "                                    y=Y_train)\n",
    "\n",
    "#X_train = transformer.transform(ds_train_images)\n",
    "#X_test  = transformer.transform(ds_test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_pipeline = Pipeline(\n",
    "steps=[\n",
    "    ('preprocessing', PreprocessingTransformer(gaussian_sigma=6,\n",
    "                                               extra_filter='median',\n",
    "                                               use_gpu=False)),\n",
    "    ('pca', PCA(n_components=47)),\n",
    "    ('knn', KNeighborsClassifier(n_neighbors=30))\n",
    "])\n",
    "\n",
    "knn_pipeline.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do a simple test of our prediction with the first 10 items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbg_idx = 2001\n",
    "extra = 10\n",
    "new_pred = knn_pipeline.predict(X_train[dbg_idx:dbg_idx+extra])\n",
    "new_pred.shape\n",
    "print(f'pred: {new_pred}\\ntruth:{Y_train[dbg_idx:(dbg_idx+extra)]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_pipeline.score(ds_test_images, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_pipeline.score(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_predict = X_train\n",
    "Y_train_predict = knn_pipeline.predict(debug_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Assuming Y_test and Y_test_predict are defined\n",
    "# Example:\n",
    "# Y_test = [true labels]\n",
    "# Y_test_predict = [predicted labels]\n",
    "\n",
    "confm = confusion_matrix(Y_train, Y_train_predict)\n",
    "\n",
    "# Create a figure\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Plot the confusion matrix as an image (heatmap)\n",
    "plt.imshow(confm, interpolation='nearest', cmap='Blues')\n",
    "\n",
    "# Add a colorbar\n",
    "plt.colorbar()\n",
    "\n",
    "# Add annotations (the counts on each cell)\n",
    "for i in range(confm.shape[0]):\n",
    "    for j in range(confm.shape[1]):\n",
    "        plt.text(j, i, f'{confm[i, j]}', ha='center', va='center', color='white')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix for 10-Class Classification')\n",
    "\n",
    "# Set ticks for the x and y axes\n",
    "plt.xticks(np.arange(10), [f'Class {i}' for i in range(10)])\n",
    "plt.yticks(np.arange(10), [f'Class {i}' for i in range(10)])\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Standalone PCA/KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import cropped-digits dataset\n",
    "dataset_cropped_digits_raw = load_dataset(\"ufldl-stanford/svhn\",\n",
    "                                          \"cropped_digits\",\n",
    "                                          cache_dir='../data/svhn/')\n",
    "\n",
    "# Get dataset subsets\n",
    "ds_train = dataset_cropped_digits_raw[\"train\"]\n",
    "ds_test = dataset_cropped_digits_raw[\"test\"]\n",
    "\n",
    "ds_train_images = np.array(ds_train[\"image\"])\n",
    "ds_test_images = np.array(ds_test[\"image\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=47)\n",
    "\n",
    "transformer = PreprocessingTransformer(gaussian_sigma=6, extra_filter='median')\n",
    "X_train_new = pca.fit_transform(transformer.transform(ds_train_images))\n",
    "X_test_new  = pca.fit_transform(transformer.transform(ds_test_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=30)\n",
    "knn.fit(X_train_new, Y_train)\n",
    "knn.score(X_test_new, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_new_predict = knn.predict(X_test_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confm = confusion_matrix(Y_test, Y_test_new_predict)\n",
    "\n",
    "# Create a figure\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Plot the confusion matrix as an image (heatmap)\n",
    "plt.imshow(confm, interpolation='nearest', cmap='Blues')\n",
    "\n",
    "# Add a colorbar\n",
    "plt.colorbar()\n",
    "\n",
    "# Add annotations (the counts on each cell)\n",
    "for i in range(confm.shape[0]):\n",
    "    for j in range(confm.shape[1]):\n",
    "        plt.text(j, i, f'{confm[i, j]}', ha='center', va='center', color='white')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix for 10-Class Classification')\n",
    "\n",
    "# Set ticks for the x and y axes\n",
    "plt.xticks(np.arange(10), [f'Class {i}' for i in range(10)])\n",
    "plt.yticks(np.arange(10), [f'Class {i}' for i in range(10)])\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aprendiendo_machin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
